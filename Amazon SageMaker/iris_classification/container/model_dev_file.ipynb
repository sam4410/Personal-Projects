{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Build an image that can do training and inference in SageMaker\r\n",
      "# This is a Python 2 image that uses the nginx, gunicorn, flask stack\r\n",
      "# for serving inferences in a stable way.\r\n",
      "\r\n",
      "FROM ubuntu:16.04\r\n",
      "\r\n",
      "MAINTAINER Amazon AI <sage-learner@amazon.com>\r\n",
      "\r\n",
      "\r\n",
      "RUN apt-get -y update && apt-get install -y --no-install-recommends \\\r\n",
      "         wget \\\r\n",
      "         python \\\r\n",
      "         nginx \\\r\n",
      "         ca-certificates \\\r\n",
      "    && rm -rf /var/lib/apt/lists/*\r\n",
      "\r\n",
      "# Here we get all python packages.\r\n",
      "# There's substantial overlap between scipy and numpy that we eliminate by\r\n",
      "# linking them together. Likewise, pip leaves the install caches populated which uses\r\n",
      "# a significant amount of space. These optimizations save a fair amount of space in the\r\n",
      "# image, which reduces start up time.\r\n",
      "RUN wget https://bootstrap.pypa.io/get-pip.py && python get-pip.py && \\\r\n",
      "    pip install numpy==1.16.2 scipy==1.2.1 scikit-learn==0.20.2 pandas flask gevent gunicorn && \\\r\n",
      "        (cd /usr/local/lib/python2.7/dist-packages/scipy/.libs; rm *; ln ../../numpy/.libs/* .) && \\\r\n",
      "        rm -rf /root/.cache\r\n",
      "\r\n",
      "# Set some environment variables. PYTHONUNBUFFERED keeps Python from buffering our standard\r\n",
      "# output stream, which means that logs can be delivered to the user quickly. PYTHONDONTWRITEBYTECODE\r\n",
      "# keeps Python from writing the .pyc files which are unnecessary in this case. We also update\r\n",
      "# PATH so that the train and serve programs are found when the container is invoked.\r\n",
      "\r\n",
      "ENV PYTHONUNBUFFERED=TRUE\r\n",
      "ENV PYTHONDONTWRITEBYTECODE=TRUE\r\n",
      "ENV PATH=\"/opt/program:${PATH}\"\r\n",
      "\r\n",
      "# Set up the program in the image\r\n",
      "COPY decision_trees /opt/program\r\n",
      "WORKDIR /opt/program\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!cat container/Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building and registering the container\n",
    "\n",
    "The following shell code shows how to build the container image using `docker build` and push the container image to ECR using `docker push`. This code is also available as the shell script `container/build-and-push.sh`, which you can run as `build-and-push.sh decision_trees` to build the image `decision_trees`. \n",
    "\n",
    "This code looks for an ECR repository in the account you're using and the current default region (if you're using a SageMaker notebook instance, this will be the region where the notebook instance was created). If the repository doesn't exist, the script will create it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "\r\n",
      "Step 1/9 : FROM ubuntu:16.04\n",
      "16.04: Pulling from library/ubuntu\n",
      "e92ed755c008: Pulling fs layer\n",
      "b9fd7cb1ff8f: Pulling fs layer\n",
      "ee690f2d57a1: Pulling fs layer\n",
      "53e3366ec435: Pulling fs layer\n",
      "53e3366ec435: Waiting\n",
      "ee690f2d57a1: Verifying Checksum\n",
      "ee690f2d57a1: Download complete\n",
      "b9fd7cb1ff8f: Verifying Checksum\n",
      "b9fd7cb1ff8f: Download complete\n",
      "53e3366ec435: Verifying Checksum\n",
      "53e3366ec435: Download complete\n",
      "e92ed755c008: Verifying Checksum\n",
      "e92ed755c008: Download complete\n",
      "e92ed755c008: Pull complete\n",
      "b9fd7cb1ff8f: Pull complete\n",
      "ee690f2d57a1: Pull complete\n",
      "53e3366ec435: Pull complete\n",
      "Digest: sha256:db6697a61d5679b7ca69dbde3dad6be0d17064d5b6b0e9f7be8d456ebb337209\n",
      "Status: Downloaded newer image for ubuntu:16.04\n",
      " ---> 005d2078bdfa\n",
      "Step 2/9 : MAINTAINER Amazon AI <sage-learner@amazon.com>\n",
      " ---> Running in 26d091a843ed\n",
      "Removing intermediate container 26d091a843ed\n",
      " ---> a6f571df3a08\n",
      "Step 3/9 : RUN apt-get -y update && apt-get install -y --no-install-recommends          wget          python          nginx          ca-certificates     && rm -rf /var/lib/apt/lists/*\n",
      " ---> Running in 7ee3c47d5eab\n",
      "Get:1 http://security.ubuntu.com/ubuntu xenial-security InRelease [109 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu xenial InRelease [247 kB]\n",
      "Get:3 http://security.ubuntu.com/ubuntu xenial-security/main amd64 Packages [1104 kB]\n",
      "Get:4 http://security.ubuntu.com/ubuntu xenial-security/restricted amd64 Packages [12.7 kB]\n",
      "Get:5 http://security.ubuntu.com/ubuntu xenial-security/universe amd64 Packages [626 kB]\n",
      "Get:6 http://security.ubuntu.com/ubuntu xenial-security/multiverse amd64 Packages [6677 B]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu xenial-updates InRelease [109 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu xenial-backports InRelease [107 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu xenial/main amd64 Packages [1558 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu xenial/restricted amd64 Packages [14.1 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu xenial/universe amd64 Packages [9827 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu xenial/multiverse amd64 Packages [176 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 Packages [1471 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu xenial-updates/restricted amd64 Packages [13.1 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu xenial-updates/universe amd64 Packages [1029 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu xenial-updates/multiverse amd64 Packages [19.7 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu xenial-backports/main amd64 Packages [7942 B]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu xenial-backports/universe amd64 Packages [8807 B]\n",
      "Fetched 16.4 MB in 2s (5952 kB/s)\n",
      "Reading package lists...\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "The following additional packages will be installed:\n",
      "  fontconfig-config fonts-dejavu-core libexpat1 libffi6 libfontconfig1\n",
      "  libfreetype6 libgd3 libgeoip1 libicu55 libidn11 libjbig0 libjpeg-turbo8\n",
      "  libjpeg8 libpng12-0 libpython-stdlib libpython2.7-minimal\n",
      "  libpython2.7-stdlib libsqlite3-0 libssl1.0.0 libtiff5 libvpx3 libx11-6\n",
      "  libx11-data libxau6 libxcb1 libxdmcp6 libxml2 libxpm4 libxslt1.1\n",
      "  mime-support nginx-common nginx-core openssl python-minimal python2.7\n",
      "  python2.7-minimal ucf\n",
      "Suggested packages:\n",
      "  libgd-tools geoip-bin fcgiwrap nginx-doc ssl-cert python-doc python-tk\n",
      "  python2.7-doc binutils binfmt-support\n",
      "Recommended packages:\n",
      "  geoip-database xml-core file\n",
      "The following NEW packages will be installed:\n",
      "  ca-certificates fontconfig-config fonts-dejavu-core libexpat1 libffi6\n",
      "  libfontconfig1 libfreetype6 libgd3 libgeoip1 libicu55 libidn11 libjbig0\n",
      "  libjpeg-turbo8 libjpeg8 libpng12-0 libpython-stdlib libpython2.7-minimal\n",
      "  libpython2.7-stdlib libsqlite3-0 libssl1.0.0 libtiff5 libvpx3 libx11-6\n",
      "  libx11-data libxau6 libxcb1 libxdmcp6 libxml2 libxpm4 libxslt1.1\n",
      "  mime-support nginx nginx-common nginx-core openssl python python-minimal\n",
      "  python2.7 python2.7-minimal ucf wget\n",
      "0 upgraded, 41 newly installed, 0 to remove and 6 not upgraded.\n",
      "Need to get 19.1 MB of archives.\n",
      "After this operation, 71.8 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu xenial/main amd64 libxau6 amd64 1:1.0.8-1 [8376 B]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libjpeg-turbo8 amd64 1.4.2-0ubuntu3.3 [111 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libpython2.7-minimal amd64 2.7.12-1ubuntu0~16.04.11 [338 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 python2.7-minimal amd64 2.7.12-1ubuntu0~16.04.11 [1261 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 python-minimal amd64 2.7.12-1~16.04 [28.1 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu xenial/main amd64 mime-support all 3.59ubuntu1 [31.0 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libexpat1 amd64 2.1.0-7ubuntu0.16.04.5 [71.5 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu xenial/main amd64 libffi6 amd64 3.2.1-4 [17.8 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libsqlite3-0 amd64 3.11.0-1ubuntu1.4 [398 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libssl1.0.0 amd64 1.0.2g-1ubuntu4.15 [1084 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libpython2.7-stdlib amd64 2.7.12-1ubuntu0~16.04.11 [1884 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 python2.7 amd64 2.7.12-1ubuntu0~16.04.11 [224 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libpython-stdlib amd64 2.7.12-1~16.04 [7768 B]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 python amd64 2.7.12-1~16.04 [137 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu xenial/main amd64 libjbig0 amd64 2.1-3.1 [26.6 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libidn11 amd64 1.32-3ubuntu1.2 [46.5 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libpng12-0 amd64 1.2.54-1ubuntu1.1 [116 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu xenial/main amd64 ucf all 3.0036 [52.9 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 openssl amd64 1.0.2g-1ubuntu4.15 [492 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 ca-certificates all 20170717~16.04.2 [167 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu xenial/main amd64 libgeoip1 amd64 1.6.9-1 [70.1 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libicu55 amd64 55.1-7ubuntu0.5 [7650 kB]\n",
      "Get:23 http://archive.ubuntu.com/ubuntu xenial/main amd64 libxdmcp6 amd64 1:1.1.2-1.1 [11.0 kB]\n",
      "Get:24 http://archive.ubuntu.com/ubuntu xenial/main amd64 libxcb1 amd64 1.11.1-1ubuntu1 [40.0 kB]\n",
      "Get:25 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libx11-data all 2:1.6.3-1ubuntu2.1 [113 kB]\n",
      "Get:26 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libx11-6 amd64 2:1.6.3-1ubuntu2.1 [570 kB]\n",
      "Get:27 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libxml2 amd64 2.9.3+dfsg1-1ubuntu0.7 [698 kB]\n",
      "Get:28 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 wget amd64 1.17.1-1ubuntu1.5 [299 kB]\n",
      "Get:29 http://archive.ubuntu.com/ubuntu xenial/main amd64 fonts-dejavu-core all 2.35-1 [1039 kB]\n",
      "Get:30 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 fontconfig-config all 2.11.94-0ubuntu1.1 [49.9 kB]\n",
      "Get:31 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libfreetype6 amd64 2.6.1-0.1ubuntu2.4 [315 kB]\n",
      "Get:32 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libfontconfig1 amd64 2.11.94-0ubuntu1.1 [131 kB]\n",
      "Get:33 http://archive.ubuntu.com/ubuntu xenial/main amd64 libjpeg8 amd64 8c-2ubuntu8 [2194 B]\n",
      "Get:34 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libtiff5 amd64 4.0.6-1ubuntu0.7 [149 kB]\n",
      "Get:35 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libvpx3 amd64 1.5.0-2ubuntu1.1 [732 kB]\n",
      "Get:36 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libxpm4 amd64 1:3.5.11-1ubuntu0.16.04.1 [33.8 kB]\n",
      "Get:37 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libgd3 amd64 2.1.1-4ubuntu0.16.04.12 [126 kB]\n",
      "Get:38 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libxslt1.1 amd64 1.1.28-2.1ubuntu0.3 [146 kB]\n",
      "Get:39 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 nginx-common all 1.10.3-0ubuntu0.16.04.5 [26.9 kB]\n",
      "Get:40 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 nginx-core amd64 1.10.3-0ubuntu0.16.04.5 [429 kB]\n",
      "Get:41 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 nginx all 1.10.3-0ubuntu0.16.04.5 [3494 B]\n",
      "\u001b[91mdebconf: delaying package configuration, since apt-utils is not installed\n",
      "\u001b[0mFetched 19.1 MB in 1s (9572 kB/s)\n",
      "Selecting previously unselected package libxau6:amd64.\r\n",
      "(Reading database ... 4781 files and directories currently installed.)\r\n",
      "Preparing to unpack .../libxau6_1%3a1.0.8-1_amd64.deb ...\r\n",
      "Unpacking libxau6:amd64 (1:1.0.8-1) ...\r\n",
      "Selecting previously unselected package libjpeg-turbo8:amd64.\r\n",
      "Preparing to unpack .../libjpeg-turbo8_1.4.2-0ubuntu3.3_amd64.deb ...\r\n",
      "Unpacking libjpeg-turbo8:amd64 (1.4.2-0ubuntu3.3) ...\r\n",
      "Selecting previously unselected package libpython2.7-minimal:amd64.\r\n",
      "Preparing to unpack .../libpython2.7-minimal_2.7.12-1ubuntu0~16.04.11_amd64.deb ...\r\n",
      "Unpacking libpython2.7-minimal:amd64 (2.7.12-1ubuntu0~16.04.11) ...\r\n",
      "Selecting previously unselected package python2.7-minimal.\r\n",
      "Preparing to unpack .../python2.7-minimal_2.7.12-1ubuntu0~16.04.11_amd64.deb ...\r\n",
      "Unpacking python2.7-minimal (2.7.12-1ubuntu0~16.04.11) ...\r\n",
      "Selecting previously unselected package python-minimal.\r\n",
      "Preparing to unpack .../python-minimal_2.7.12-1~16.04_amd64.deb ...\r\n",
      "Unpacking python-minimal (2.7.12-1~16.04) ...\r\n",
      "Selecting previously unselected package mime-support.\r\n",
      "Preparing to unpack .../mime-support_3.59ubuntu1_all.deb ...\r\n",
      "Unpacking mime-support (3.59ubuntu1) ...\r\n",
      "Selecting previously unselected package libexpat1:amd64.\r\n",
      "Preparing to unpack .../libexpat1_2.1.0-7ubuntu0.16.04.5_amd64.deb ...\r\n",
      "Unpacking libexpat1:amd64 (2.1.0-7ubuntu0.16.04.5) ...\r\n",
      "Selecting previously unselected package libffi6:amd64.\r\n",
      "Preparing to unpack .../libffi6_3.2.1-4_amd64.deb ...\r\n",
      "Unpacking libffi6:amd64 (3.2.1-4) ...\r\n",
      "Selecting previously unselected package libsqlite3-0:amd64.\r\n",
      "Preparing to unpack .../libsqlite3-0_3.11.0-1ubuntu1.4_amd64.deb ...\r\n",
      "Unpacking libsqlite3-0:amd64 (3.11.0-1ubuntu1.4) ...\r\n",
      "Selecting previously unselected package libssl1.0.0:amd64.\r\n",
      "Preparing to unpack .../libssl1.0.0_1.0.2g-1ubuntu4.15_amd64.deb ...\r\n",
      "Unpacking libssl1.0.0:amd64 (1.0.2g-1ubuntu4.15) ...\r\n",
      "Selecting previously unselected package libpython2.7-stdlib:amd64.\r\n",
      "Preparing to unpack .../libpython2.7-stdlib_2.7.12-1ubuntu0~16.04.11_amd64.deb ...\r\n",
      "Unpacking libpython2.7-stdlib:amd64 (2.7.12-1ubuntu0~16.04.11) ...\r\n",
      "Selecting previously unselected package python2.7.\r\n",
      "Preparing to unpack .../python2.7_2.7.12-1ubuntu0~16.04.11_amd64.deb ...\r\n",
      "Unpacking python2.7 (2.7.12-1ubuntu0~16.04.11) ...\r\n",
      "Selecting previously unselected package libpython-stdlib:amd64.\r\n",
      "Preparing to unpack .../libpython-stdlib_2.7.12-1~16.04_amd64.deb ...\r\n",
      "Unpacking libpython-stdlib:amd64 (2.7.12-1~16.04) ...\r\n",
      "Processing triggers for libc-bin (2.23-0ubuntu11) ...\r\n",
      "Setting up libpython2.7-minimal:amd64 (2.7.12-1ubuntu0~16.04.11) ...\r\n",
      "Setting up python2.7-minimal (2.7.12-1ubuntu0~16.04.11) ...\r\n",
      "Linking and byte-compiling packages for runtime python2.7...\r\n",
      "Setting up python-minimal (2.7.12-1~16.04) ...\r\n",
      "Selecting previously unselected package python.\r\n",
      "(Reading database ... 5603 files and directories currently installed.)\r\n",
      "Preparing to unpack .../python_2.7.12-1~16.04_amd64.deb ...\r\n",
      "Unpacking python (2.7.12-1~16.04) ...\r\n",
      "Selecting previously unselected package libjbig0:amd64.\r\n",
      "Preparing to unpack .../libjbig0_2.1-3.1_amd64.deb ...\r\n",
      "Unpacking libjbig0:amd64 (2.1-3.1) ...\r\n",
      "Selecting previously unselected package libidn11:amd64.\r\n",
      "Preparing to unpack .../libidn11_1.32-3ubuntu1.2_amd64.deb ...\r\n",
      "Unpacking libidn11:amd64 (1.32-3ubuntu1.2) ...\r\n",
      "Selecting previously unselected package libpng12-0:amd64.\r\n",
      "Preparing to unpack .../libpng12-0_1.2.54-1ubuntu1.1_amd64.deb ...\r\n",
      "Unpacking libpng12-0:amd64 (1.2.54-1ubuntu1.1) ...\r\n",
      "Selecting previously unselected package ucf.\r\n",
      "Preparing to unpack .../archives/ucf_3.0036_all.deb ...\r\n",
      "Moving old data out of the way\r\n",
      "Unpacking ucf (3.0036) ...\r\n",
      "Selecting previously unselected package openssl.\r\n",
      "Preparing to unpack .../openssl_1.0.2g-1ubuntu4.15_amd64.deb ...\r\n",
      "Unpacking openssl (1.0.2g-1ubuntu4.15) ...\r\n",
      "Selecting previously unselected package ca-certificates.\r\n",
      "Preparing to unpack .../ca-certificates_20170717~16.04.2_all.deb ...\r\n",
      "Unpacking ca-certificates (20170717~16.04.2) ...\r\n",
      "Selecting previously unselected package libgeoip1:amd64.\r\n",
      "Preparing to unpack .../libgeoip1_1.6.9-1_amd64.deb ...\r\n",
      "Unpacking libgeoip1:amd64 (1.6.9-1) ...\r\n",
      "Selecting previously unselected package libicu55:amd64.\r\n",
      "Preparing to unpack .../libicu55_55.1-7ubuntu0.5_amd64.deb ...\r\n",
      "Unpacking libicu55:amd64 (55.1-7ubuntu0.5) ...\r\n",
      "Selecting previously unselected package libxdmcp6:amd64.\r\n",
      "Preparing to unpack .../libxdmcp6_1%3a1.1.2-1.1_amd64.deb ...\r\n",
      "Unpacking libxdmcp6:amd64 (1:1.1.2-1.1) ...\r\n",
      "Selecting previously unselected package libxcb1:amd64.\r\n",
      "Preparing to unpack .../libxcb1_1.11.1-1ubuntu1_amd64.deb ...\r\n",
      "Unpacking libxcb1:amd64 (1.11.1-1ubuntu1) ...\r\n",
      "Selecting previously unselected package libx11-data.\r\n",
      "Preparing to unpack .../libx11-data_2%3a1.6.3-1ubuntu2.1_all.deb ...\r\n",
      "Unpacking libx11-data (2:1.6.3-1ubuntu2.1) ...\r\n",
      "Selecting previously unselected package libx11-6:amd64.\r\n",
      "Preparing to unpack .../libx11-6_2%3a1.6.3-1ubuntu2.1_amd64.deb ...\r\n",
      "Unpacking libx11-6:amd64 (2:1.6.3-1ubuntu2.1) ...\r\n",
      "Selecting previously unselected package libxml2:amd64.\r\n",
      "Preparing to unpack .../libxml2_2.9.3+dfsg1-1ubuntu0.7_amd64.deb ...\r\n",
      "Unpacking libxml2:amd64 (2.9.3+dfsg1-1ubuntu0.7) ...\r\n",
      "Selecting previously unselected package wget.\r\n",
      "Preparing to unpack .../wget_1.17.1-1ubuntu1.5_amd64.deb ...\r\n",
      "Unpacking wget (1.17.1-1ubuntu1.5) ...\r\n",
      "Selecting previously unselected package fonts-dejavu-core.\r\n",
      "Preparing to unpack .../fonts-dejavu-core_2.35-1_all.deb ...\r\n",
      "Unpacking fonts-dejavu-core (2.35-1) ...\r\n",
      "Selecting previously unselected package fontconfig-config.\r\n",
      "Preparing to unpack .../fontconfig-config_2.11.94-0ubuntu1.1_all.deb ...\r\n",
      "Unpacking fontconfig-config (2.11.94-0ubuntu1.1) ...\r\n",
      "Selecting previously unselected package libfreetype6:amd64.\r\n",
      "Preparing to unpack .../libfreetype6_2.6.1-0.1ubuntu2.4_amd64.deb ...\r\n",
      "Unpacking libfreetype6:amd64 (2.6.1-0.1ubuntu2.4) ...\r\n",
      "Selecting previously unselected package libfontconfig1:amd64.\r\n",
      "Preparing to unpack .../libfontconfig1_2.11.94-0ubuntu1.1_amd64.deb ...\r\n",
      "Unpacking libfontconfig1:amd64 (2.11.94-0ubuntu1.1) ...\r\n",
      "Selecting previously unselected package libjpeg8:amd64.\r\n",
      "Preparing to unpack .../libjpeg8_8c-2ubuntu8_amd64.deb ...\r\n",
      "Unpacking libjpeg8:amd64 (8c-2ubuntu8) ...\r\n",
      "Selecting previously unselected package libtiff5:amd64.\r\n",
      "Preparing to unpack .../libtiff5_4.0.6-1ubuntu0.7_amd64.deb ...\r\n",
      "Unpacking libtiff5:amd64 (4.0.6-1ubuntu0.7) ...\r\n",
      "Selecting previously unselected package libvpx3:amd64.\r\n",
      "Preparing to unpack .../libvpx3_1.5.0-2ubuntu1.1_amd64.deb ...\r\n",
      "Unpacking libvpx3:amd64 (1.5.0-2ubuntu1.1) ...\r\n",
      "Selecting previously unselected package libxpm4:amd64.\r\n",
      "Preparing to unpack .../libxpm4_1%3a3.5.11-1ubuntu0.16.04.1_amd64.deb ...\r\n",
      "Unpacking libxpm4:amd64 (1:3.5.11-1ubuntu0.16.04.1) ...\r\n",
      "Selecting previously unselected package libgd3:amd64.\r\n",
      "Preparing to unpack .../libgd3_2.1.1-4ubuntu0.16.04.12_amd64.deb ...\r\n",
      "Unpacking libgd3:amd64 (2.1.1-4ubuntu0.16.04.12) ...\r\n",
      "Selecting previously unselected package libxslt1.1:amd64.\r\n",
      "Preparing to unpack .../libxslt1.1_1.1.28-2.1ubuntu0.3_amd64.deb ...\r\n",
      "Unpacking libxslt1.1:amd64 (1.1.28-2.1ubuntu0.3) ...\r\n",
      "Selecting previously unselected package nginx-common.\r\n",
      "Preparing to unpack .../nginx-common_1.10.3-0ubuntu0.16.04.5_all.deb ...\r\n",
      "Unpacking nginx-common (1.10.3-0ubuntu0.16.04.5) ...\r\n",
      "Selecting previously unselected package nginx-core.\r\n",
      "Preparing to unpack .../nginx-core_1.10.3-0ubuntu0.16.04.5_amd64.deb ...\r\n",
      "Unpacking nginx-core (1.10.3-0ubuntu0.16.04.5) ...\r\n",
      "Selecting previously unselected package nginx.\r\n",
      "Preparing to unpack .../nginx_1.10.3-0ubuntu0.16.04.5_all.deb ...\r\n",
      "Unpacking nginx (1.10.3-0ubuntu0.16.04.5) ...\r\n",
      "Processing triggers for libc-bin (2.23-0ubuntu11) ...\r\n",
      "Processing triggers for systemd (229-4ubuntu21.27) ...\r\n",
      "Setting up libxau6:amd64 (1:1.0.8-1) ...\r\n",
      "Setting up libjpeg-turbo8:amd64 (1.4.2-0ubuntu3.3) ...\r\n",
      "Setting up mime-support (3.59ubuntu1) ...\r\n",
      "Setting up libexpat1:amd64 (2.1.0-7ubuntu0.16.04.5) ...\r\n",
      "Setting up libffi6:amd64 (3.2.1-4) ...\r\n",
      "Setting up libsqlite3-0:amd64 (3.11.0-1ubuntu1.4) ...\r\n",
      "Setting up libssl1.0.0:amd64 (1.0.2g-1ubuntu4.15) ...\r\n",
      "debconf: unable to initialize frontend: Dialog\r\n",
      "debconf: (TERM is not set, so the dialog frontend is not usable.)\r\n",
      "debconf: falling back to frontend: Readline\r\n",
      "debconf: unable to initialize frontend: Readline\r\n",
      "debconf: (Can't locate Term/ReadLine.pm in @INC (you may need to install the Term::ReadLine module) (@INC contains: /etc/perl /usr/local/lib/x86_64-linux-gnu/perl/5.22.1 /usr/local/share/perl/5.22.1 /usr/lib/x86_64-linux-gnu/perl5/5.22 /usr/share/perl5 /usr/lib/x86_64-linux-gnu/perl/5.22 /usr/share/perl/5.22 /usr/local/lib/site_perl /usr/lib/x86_64-linux-gnu/perl-base .) at /usr/share/perl5/Debconf/FrontEnd/Readline.pm line 7.)\r\n",
      "debconf: falling back to frontend: Teletype\r\n",
      "Setting up libpython2.7-stdlib:amd64 (2.7.12-1ubuntu0~16.04.11) ...\r\n",
      "Setting up python2.7 (2.7.12-1ubuntu0~16.04.11) ...\r\n",
      "Setting up libpython-stdlib:amd64 (2.7.12-1~16.04) ...\r\n",
      "Setting up python (2.7.12-1~16.04) ...\r\n",
      "Setting up libjbig0:amd64 (2.1-3.1) ...\r\n",
      "Setting up libidn11:amd64 (1.32-3ubuntu1.2) ...\r\n",
      "Setting up libpng12-0:amd64 (1.2.54-1ubuntu1.1) ...\r\n",
      "Setting up ucf (3.0036) ...\r\n",
      "debconf: unable to initialize frontend: Dialog\r\n",
      "debconf: (TERM is not set, so the dialog frontend is not usable.)\r\n",
      "debconf: falling back to frontend: Readline\r\n",
      "debconf: unable to initialize frontend: Readline\r\n",
      "debconf: (Can't locate Term/ReadLine.pm in @INC (you may need to install the Term::ReadLine module) (@INC contains: /etc/perl /usr/local/lib/x86_64-linux-gnu/perl/5.22.1 /usr/local/share/perl/5.22.1 /usr/lib/x86_64-linux-gnu/perl5/5.22 /usr/share/perl5 /usr/lib/x86_64-linux-gnu/perl/5.22 /usr/share/perl/5.22 /usr/local/lib/site_perl /usr/lib/x86_64-linux-gnu/perl-base .) at /usr/share/perl5/Debconf/FrontEnd/Readline.pm line 7.)\r\n",
      "debconf: falling back to frontend: Teletype\r\n",
      "Setting up openssl (1.0.2g-1ubuntu4.15) ...\r\n",
      "Setting up ca-certificates (20170717~16.04.2) ...\r\n",
      "debconf: unable to initialize frontend: Dialog\r\n",
      "debconf: (TERM is not set, so the dialog frontend is not usable.)\r\n",
      "debconf: falling back to frontend: Readline\r\n",
      "debconf: unable to initialize frontend: Readline\r\n",
      "debconf: (Can't locate Term/ReadLine.pm in @INC (you may need to install the Term::ReadLine module) (@INC contains: /etc/perl /usr/local/lib/x86_64-linux-gnu/perl/5.22.1 /usr/local/share/perl/5.22.1 /usr/lib/x86_64-linux-gnu/perl5/5.22 /usr/share/perl5 /usr/lib/x86_64-linux-gnu/perl/5.22 /usr/share/perl/5.22 /usr/local/lib/site_perl /usr/lib/x86_64-linux-gnu/perl-base .) at /usr/share/perl5/Debconf/FrontEnd/Readline.pm line 7.)\r\n",
      "debconf: falling back to frontend: Teletype\r\n",
      "Setting up libgeoip1:amd64 (1.6.9-1) ...\r\n",
      "Setting up libicu55:amd64 (55.1-7ubuntu0.5) ...\r\n",
      "Setting up libxdmcp6:amd64 (1:1.1.2-1.1) ...\r\n",
      "Setting up libxcb1:amd64 (1.11.1-1ubuntu1) ...\r\n",
      "Setting up libx11-data (2:1.6.3-1ubuntu2.1) ...\r\n",
      "Setting up libx11-6:amd64 (2:1.6.3-1ubuntu2.1) ...\r\n",
      "Setting up libxml2:amd64 (2.9.3+dfsg1-1ubuntu0.7) ...\r\n",
      "Setting up wget (1.17.1-1ubuntu1.5) ...\r\n",
      "Setting up fonts-dejavu-core (2.35-1) ...\r\n",
      "Setting up fontconfig-config (2.11.94-0ubuntu1.1) ...\r\n",
      "Setting up libfreetype6:amd64 (2.6.1-0.1ubuntu2.4) ...\r\n",
      "Setting up libfontconfig1:amd64 (2.11.94-0ubuntu1.1) ...\r\n",
      "Setting up libjpeg8:amd64 (8c-2ubuntu8) ...\r\n",
      "Setting up libtiff5:amd64 (4.0.6-1ubuntu0.7) ...\r\n",
      "Setting up libvpx3:amd64 (1.5.0-2ubuntu1.1) ...\r\n",
      "Setting up libxpm4:amd64 (1:3.5.11-1ubuntu0.16.04.1) ...\r\n",
      "Setting up libgd3:amd64 (2.1.1-4ubuntu0.16.04.12) ...\r\n",
      "Setting up libxslt1.1:amd64 (1.1.28-2.1ubuntu0.3) ...\r\n",
      "Setting up nginx-common (1.10.3-0ubuntu0.16.04.5) ...\r\n",
      "debconf: unable to initialize frontend: Dialog\r\n",
      "debconf: (TERM is not set, so the dialog frontend is not usable.)\r\n",
      "debconf: falling back to frontend: Readline\r\n",
      "debconf: unable to initialize frontend: Readline\r\n",
      "debconf: (Can't locate Term/ReadLine.pm in @INC (you may need to install the Term::ReadLine module) (@INC contains: /etc/perl /usr/local/lib/x86_64-linux-gnu/perl/5.22.1 /usr/local/share/perl/5.22.1 /usr/lib/x86_64-linux-gnu/perl5/5.22 /usr/share/perl5 /usr/lib/x86_64-linux-gnu/perl/5.22 /usr/share/perl/5.22 /usr/local/lib/site_perl /usr/lib/x86_64-linux-gnu/perl-base .) at /usr/share/perl5/Debconf/FrontEnd/Readline.pm line 7.)\r\n",
      "debconf: falling back to frontend: Teletype\r\n",
      "Setting up nginx-core (1.10.3-0ubuntu0.16.04.5) ...\r\n",
      "invoke-rc.d: could not determine current runlevel\r\n",
      "invoke-rc.d: policy-rc.d denied execution of start.\r\n",
      "Setting up nginx (1.10.3-0ubuntu0.16.04.5) ...\r\n",
      "Processing triggers for libc-bin (2.23-0ubuntu11) ...\r\n",
      "Processing triggers for ca-certificates (20170717~16.04.2) ...\r\n",
      "Updating certificates in /etc/ssl/certs...\r\n",
      "148 added, 0 removed; done.\r\n",
      "Running hooks in /etc/ca-certificates/update.d...\r\n",
      "done.\r\n",
      "Processing triggers for systemd (229-4ubuntu21.27) ...\r\n",
      "Removing intermediate container 7ee3c47d5eab\n",
      " ---> 805f954a8851\n",
      "Step 4/9 : RUN wget https://bootstrap.pypa.io/get-pip.py && python get-pip.py &&     pip install numpy==1.16.2 scipy==1.2.1 scikit-learn==0.20.2 pandas flask gevent gunicorn &&         (cd /usr/local/lib/python2.7/dist-packages/scipy/.libs; rm *; ln ../../numpy/.libs/* .) &&         rm -rf /root/.cache\n",
      " ---> Running in fdde03fd7eae\n",
      "\u001b[91m--2020-05-17 14:42:33--  https://bootstrap.pypa.io/get-pip.py\n",
      "\u001b[0m\u001b[91mResolving bootstrap.pypa.io (bootstrap.pypa.io)... \u001b[0m\u001b[91m199.232.64.175, 2a04:4e42:3b::175\n",
      "Connecting to bootstrap.pypa.io (bootstrap.pypa.io)|199.232.64.175|:443... \u001b[0m\u001b[91mconnected.\n",
      "\u001b[0m\u001b[91mHTTP request sent, awaiting response... \u001b[0m\u001b[91m200 OK\n",
      "Length: 1868059 (1.8M) [text/x-python]\n",
      "\u001b[0m\u001b[91mSaving to: 'get-pip.py'\n",
      "\u001b[0m\u001b[91m\n",
      "     0K ..\u001b[0m\u001b[91m..\u001b[0m\u001b[91m......\u001b[0m\u001b[91m ..\u001b[0m\u001b[91m......\u001b[0m\u001b[91m.. ...\u001b[0m\u001b[91m...\u001b[0m\u001b[91m..\u001b[0m\u001b[91m.. .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m...  2% 2.12M 1s\n",
      "    50K .....\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m.....  5% 4.31M 1s\n",
      "   100K ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.. .....\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m.......  8%  165M\u001b[0m\u001b[91m 0s\n",
      "   150K .\u001b[0m\u001b[91m.....\u001b[0m\u001b[91m...\u001b[0m\u001b[91m. .......... ...\u001b[0m\u001b[91m..\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m......... 10% 4.38M 0s\n",
      "   200K .......\u001b[0m\u001b[91m... .......... ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m....\u001b[0m\u001b[91m....\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... 13%  106M 0s\n",
      "   250K .....\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.... ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m......... .......\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m..... 16%  185M 0s\n",
      "   300K ...\u001b[0m\u001b[91m....... .........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m..... .......... 19%  308M 0s\n",
      "   350K \u001b[0m\u001b[91m.\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... .......... ...\u001b[0m\u001b[91m....... ........\u001b[0m\u001b[91m.\u001b[0m\u001b[91m. 21% 4.56M 0s\n",
      "   400K .......\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m..... .......... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. \u001b[0m\u001b[91m.......\u001b[0m\u001b[91m... 24%  164M 0s\n",
      "   450K .....\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... ..........\u001b[0m\u001b[91m 27%  215M 0s\n",
      "   500K ...\u001b[0m\u001b[91m.\u001b[0m\u001b[91m...... .\u001b[0m\u001b[91m......... .....\u001b[0m\u001b[91m..\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m....... 30% 4.49M 0s\n",
      "   550K ........\u001b[0m\u001b[91m.\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. 32%  123M 0s\n",
      "   600K .......\u001b[0m\u001b[91m... .......... .\u001b[0m\u001b[91m..\u001b[0m\u001b[91m....... ......\u001b[0m\u001b[91m...\u001b[0m\u001b[91m. ....\u001b[0m\u001b[91m...\u001b[0m\u001b[91m... 35%  139M 0s\n",
      "   650K .....\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m..... 38%  173M 0s\n",
      "   700K \u001b[0m\u001b[91m...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......... .....\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m....... 41%  144M 0s\n",
      "   750K .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. 43%  211M 0s\n",
      "   800K .......\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... 46%  257M 0s\n",
      "   850K .....\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m..... 49%  258M 0s\n",
      "   900K ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m....... 52%  246M 0s\n",
      "   950K .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m..... .......... .\u001b[0m\u001b[91m......... 54%  221M 0s\n",
      "  1000K ...\u001b[0m\u001b[91m....\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m....... ......\u001b[0m\u001b[91m...\u001b[0m\u001b[91m. .......... 57% 5.30M 0s\u001b[0m\u001b[91m\n",
      "  1050K .....\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... .......... 60%  165M 0s\u001b[0m\u001b[91m\n",
      "  1100K ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......... .....\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m....... 63%  180M 0s\n",
      "  1150K .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m.\u001b[0m\u001b[91m .......\u001b[0m\u001b[91m... .......... ...\u001b[0m\u001b[91m....... ........\u001b[0m\u001b[91m.\u001b[0m\u001b[91m. 65%  192M 0s\n",
      "  1200K .......\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m..\u001b[0m\u001b[91m... ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... 68%  153M 0s\n",
      "  1250K .....\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m..... 71%  201M 0s\n",
      "  1300K ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m......... .......\u001b[0m\u001b[91m... .......... ...\u001b[0m\u001b[91m....... 74%  307M 0s\n",
      "  1350K .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m......... 76%  303M 0s\n",
      "  1400K ......\u001b[0m\u001b[91m.\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m....... .........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... 79%  318M 0s\n",
      "  1450K .....\u001b[0m\u001b[91m..... .......... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... .......... 82%  317M 0s\n",
      "  1500K\u001b[0m\u001b[91m ...\u001b[0m\u001b[91m....... .......\u001b[0m\u001b[91m..\u001b[0m\u001b[91m. .......... .....\u001b[0m\u001b[91m..... .......... 84% 4.98M\u001b[0m\u001b[91m 0s\n",
      "  1550K .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.. ..\u001b[0m\u001b[91m...\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. 87%  125M 0s\n",
      "  1600K .......\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m......... .......\u001b[0m\u001b[91m... 90%  270M 0s\n",
      "  1650K .....\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m..... 93%  254M 0s\n",
      "  1700K ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... .......... ...\u001b[0m\u001b[91m....... 95%  252M 0s\n",
      "  1750K .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m..... .......... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. 98%  249M 0s\n",
      "  1800K ...\u001b[0m\u001b[91m....\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m.                          \u001b[0m\u001b[91m  100%  225M=0.09s\u001b[0m\u001b[91m\n",
      "\n",
      "\u001b[0m\u001b[91m2020-05-17 14:42:33 (19.1 MB/s) - 'get-pip.py' saved [1868059/1868059]\n",
      "\n",
      "\u001b[0m\u001b[91mDEPRECATION: Python 2.7 reached the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 is no longer maintained. pip 21.0 will drop support for Python 2.7 in January 2021. More details about Python 2 support in pip, can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support\n",
      "\u001b[0mCollecting pip\n",
      "  Downloading pip-20.1-py2.py3-none-any.whl (1.5 MB)\n",
      "Collecting setuptools\n",
      "  Downloading setuptools-44.1.0-py2.py3-none-any.whl (583 kB)\n",
      "Collecting wheel\n",
      "  Downloading wheel-0.34.2-py2.py3-none-any.whl (26 kB)\n",
      "Installing collected packages: pip, setuptools, wheel\n",
      "Successfully installed pip-20.1 setuptools-44.1.0 wheel-0.34.2\n",
      "\u001b[91mDEPRECATION: Python 2.7 reached the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 is no longer maintained. pip 21.0 will drop support for Python 2.7 in January 2021. More details about Python 2 support in pip, can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support\n",
      "\u001b[0mCollecting numpy==1.16.2\n",
      "  Downloading numpy-1.16.2-cp27-cp27mu-manylinux1_x86_64.whl (17.0 MB)\n",
      "Collecting scipy==1.2.1\n",
      "  Downloading scipy-1.2.1-cp27-cp27mu-manylinux1_x86_64.whl (24.8 MB)\n",
      "Collecting scikit-learn==0.20.2\n",
      "  Downloading scikit_learn-0.20.2-cp27-cp27mu-manylinux1_x86_64.whl (5.5 MB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-0.24.2-cp27-cp27mu-manylinux1_x86_64.whl (10.1 MB)\n",
      "Collecting flask\n",
      "  Downloading Flask-1.1.2-py2.py3-none-any.whl (94 kB)\n",
      "Collecting gevent\n",
      "  Downloading gevent-20.5.0-cp27-cp27mu-manylinux2010_x86_64.whl (4.7 MB)\n",
      "Collecting gunicorn\n",
      "  Downloading gunicorn-19.10.0-py2.py3-none-any.whl (113 kB)\n",
      "Collecting python-dateutil>=2.5.0\n",
      "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "Collecting pytz>=2011k\n",
      "  Downloading pytz-2020.1-py2.py3-none-any.whl (510 kB)\n",
      "Collecting click>=5.1\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Collecting itsdangerous>=0.24\n",
      "  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting Werkzeug>=0.15\n",
      "  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "Collecting Jinja2>=2.10.1\n",
      "  Downloading Jinja2-2.11.2-py2.py3-none-any.whl (125 kB)\n",
      "Collecting greenlet>=0.4.14; platform_python_implementation == \"CPython\"\n",
      "  Downloading greenlet-0.4.15-cp27-cp27mu-manylinux1_x86_64.whl (39 kB)\n",
      "Collecting six>=1.5\n",
      "  Downloading six-1.14.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting MarkupSafe>=0.23\n",
      "  Downloading MarkupSafe-1.1.1-cp27-cp27mu-manylinux1_x86_64.whl (24 kB)\n",
      "Installing collected packages: numpy, scipy, scikit-learn, six, python-dateutil, pytz, pandas, click, itsdangerous, Werkzeug, MarkupSafe, Jinja2, flask, greenlet, gevent, gunicorn\n",
      "Successfully installed Jinja2-2.11.2 MarkupSafe-1.1.1 Werkzeug-1.0.1 click-7.1.2 flask-1.1.2 gevent-20.5.0 greenlet-0.4.15 gunicorn-19.10.0 itsdangerous-1.1.0 numpy-1.16.2 pandas-0.24.2 python-dateutil-2.8.1 pytz-2020.1 scikit-learn-0.20.2 scipy-1.2.1 six-1.14.0\n",
      "Removing intermediate container fdde03fd7eae\n",
      " ---> d3263664ca1a\n",
      "Step 5/9 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Running in a3c658e21b2f\n",
      "Removing intermediate container a3c658e21b2f\n",
      " ---> 7b59fe2f4c09\n",
      "Step 6/9 : ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      " ---> Running in afded6293698\n",
      "Removing intermediate container afded6293698\n",
      " ---> 1a26c5249118\n",
      "Step 7/9 : ENV PATH=\"/opt/program:${PATH}\"\n",
      " ---> Running in 89a15097a5ce\n",
      "Removing intermediate container 89a15097a5ce\n",
      " ---> 82282fb28634\n",
      "Step 8/9 : COPY decision_trees /opt/program\n",
      " ---> 804980a2da27\n",
      "Step 9/9 : WORKDIR /opt/program\n",
      " ---> Running in f242bed95fa9\n",
      "Removing intermediate container f242bed95fa9\n",
      " ---> dc0ccb5ddc09\n",
      "Successfully built dc0ccb5ddc09\n",
      "Successfully tagged sagemaker-decision-trees:latest\n",
      "The push refers to repository [434418615032.dkr.ecr.us-east-2.amazonaws.com/sagemaker-decision-trees]\n",
      "ecd680aaf5d5: Preparing\n",
      "61c7543fe5d0: Preparing\n",
      "3fa478ecb630: Preparing\n",
      "64d2e4aaa54c: Preparing\n",
      "0d3833376c2f: Preparing\n",
      "4a048ea09024: Preparing\n",
      "b592b5433bbf: Preparing\n",
      "4a048ea09024: Waiting\n",
      "b592b5433bbf: Waiting\n",
      "ecd680aaf5d5: Pushed\n",
      "0d3833376c2f: Pushed\n",
      "64d2e4aaa54c: Pushed\n",
      "4a048ea09024: Pushed\n",
      "3fa478ecb630: Pushed\n",
      "b592b5433bbf: Pushed\n",
      "61c7543fe5d0: Pushed\n",
      "latest: digest: sha256:4fa1500e0a526dff211ecc78c8d49715d3c800fb290d4e625655c717def9ece2 size: 1782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=sagemaker-decision-trees\n",
    "\n",
    "cd container\n",
    "\n",
    "chmod +x decision_trees/train\n",
    "chmod +x decision_trees/serve\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build  -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing your algorithm on your local machine or on an Amazon SageMaker notebook instance\n",
    "\n",
    "While you're first packaging an algorithm use with Amazon SageMaker, you probably want to test it yourself to make sure it's working right. In the directory `container/local_test`, there is a framework for doing this. It includes three shell scripts for running and using the container and a directory structure that mimics the one outlined above.\n",
    "\n",
    "The scripts are:\n",
    "\n",
    "* `train_local.sh`: Run this with the name of the image and it will run training on the local tree. For example, you can run `$ ./train_local.sh sagemaker-decision-trees`. It will generate a model under the `/test_dir/model` directory. You'll want to modify the directory `test_dir/input/data/...` to be set up with the correct channels and data for your algorithm. Also, you'll want to modify the file `input/config/hyperparameters.json` to have the hyperparameter settings that you want to test (as strings).\n",
    "* `serve_local.sh`: Run this with the name of the image once you've trained the model and it should serve the model. For example, you can run `$ ./serve_local.sh sagemaker-decision-trees`. It will run and wait for requests. Simply use the keyboard interrupt to stop it.\n",
    "* `predict.sh`: Run this with the name of a payload file and (optionally) the HTTP content type you want. The content type will default to `text/csv`. For example, you can run `$ ./predict.sh payload.csv text/csv`.\n",
    "\n",
    "The directories as shipped are set up to test the decision trees sample algorithm presented here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Using your Algorithm in Amazon SageMaker\n",
    "\n",
    "Once you have your container packaged, you can use it to train models and use the model for hosting or batch transforms. Let's do that with the algorithm we made above.\n",
    "\n",
    "## Set up the environment\n",
    "\n",
    "Here we specify a bucket to use and the role that will be used for working with SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 prefix\n",
    "prefix = 'efmachinelearning/Manoj'\n",
    "\n",
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the session\n",
    "\n",
    "The session remembers our connection parameters to SageMaker. We'll use it to perform all of our SageMaker operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker as sage\n",
    "from time import gmtime, strftime\n",
    "\n",
    "sess = sage.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the data for training\n",
    "\n",
    "When training large models with huge amounts of data, you'll typically use big data tools, like Amazon Athena, AWS Glue, or Amazon EMR, to create your data in S3. For the purposes of this example, we're using some the classic [Iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set), which we have included. \n",
    "\n",
    "We can use use the tools provided by the SageMaker Python SDK to upload the data to a default bucket. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIRECTORY = 'data'\n",
    "\n",
    "data_location = sess.upload_data(WORK_DIRECTORY, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an estimator and fit the model\n",
    "\n",
    "In order to use SageMaker to fit our algorithm, we'll create an `Estimator` that defines how to use the container to train. This includes the configuration we need to invoke SageMaker training:\n",
    "\n",
    "* The __container name__. This is constructed as in the shell commands above.\n",
    "* The __role__. As defined above.\n",
    "* The __instance count__ which is the number of machines to use for training.\n",
    "* The __instance type__ which is the type of machine to use for training.\n",
    "* The __output path__ determines where the model artifact will be written.\n",
    "* The __session__ is the SageMaker session object that we defined above.\n",
    "\n",
    "Then we use fit() on the estimator to train against the data that we uploaded above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 14:45:52 Starting - Starting the training job...\n",
      "2020-05-17 14:45:55 Starting - Launching requested ML instances......\n",
      "2020-05-17 14:46:58 Starting - Preparing the instances for training...\n",
      "2020-05-17 14:47:47 Downloading - Downloading input data\n",
      "2020-05-17 14:47:47 Training - Downloading the training image...\n",
      "2020-05-17 14:48:20 Uploading - Uploading generated training model\u001b[34mStarting the training.\u001b[0m\n",
      "\u001b[34mTraining complete.\u001b[0m\n",
      "\n",
      "2020-05-17 14:48:26 Completed - Training job completed\n",
      "Training seconds: 45\n",
      "Billable seconds: 45\n"
     ]
    }
   ],
   "source": [
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = sess.boto_session.region_name\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/sagemaker-decision-trees:latest'.format(account, region)\n",
    "\n",
    "tree = sage.estimator.Estimator(image,\n",
    "                       role, 1, 'ml.c4.2xlarge',\n",
    "                       output_path=\"s3://{}/output\".format(sess.default_bucket()),\n",
    "                       sagemaker_session=sess)\n",
    "\n",
    "tree.fit(data_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hosting your model\n",
    "You can use a trained model to get real time predictions using HTTP endpoint. Follow these steps to walk you through the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the model\n",
    "\n",
    "Deploying the model to SageMaker hosting just requires a `deploy` call on the fitted model. This call takes an instance count, instance type, and optionally serializer and deserializer functions. These are used when the resulting predictor is created on the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import csv_serializer\n",
    "predictor = tree.deploy(1, 'ml.m4.xlarge', serializer=csv_serializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose some data and use it for a prediction\n",
    "\n",
    "In order to do some predictions, we'll extract some of the data we used for training and do predictions against it. This is, of course, bad statistical practice, but a good way to see how the mechanism works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>versicolor</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>setosa</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>virginica</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0    1    2    3    4\n",
       "57   versicolor  4.9  2.4  3.3  1.0\n",
       "29       setosa  4.7  3.2  1.6  0.2\n",
       "124   virginica  6.7  3.3  5.7  2.1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape=pd.read_csv(\"data/iris.csv\", header=None)\n",
    "shape.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       1    2    3    4\n",
       "87   6.3  2.3  4.4  1.3\n",
       "74   6.4  2.9  4.3  1.3\n",
       "127  6.1  3.0  4.9  1.8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the label column in the training set\n",
    "shape.drop(shape.columns[[0]],axis=1,inplace=True)\n",
    "shape.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "a = [50*i for i in range(3)]\n",
    "b = [40+i for i in range(10)]\n",
    "indices = [i+j for i,j in itertools.product(a,b)]\n",
    "\n",
    "test_data=shape.iloc[indices[:-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction is as easy as calling predict with the predictor we got back from deploy and the data we want to do predictions with. The serializers take care of doing the data conversions for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(predictor.predict(test_data.values).decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional cleanup\n",
    "When you're done with the endpoint, you'll want to clean it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.delete_endpoint(predictor.endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Batch Transform Job\n",
    "You can use a trained model to get inference on large data sets by using [Amazon SageMaker Batch Transform](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-batch.html). A batch transform job takes your input data S3 location and outputs the predictions to the specified S3 output folder. Similar to hosting, you can extract inferences for training data to test batch transform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Transform Job\n",
    "We'll create an `Transformer` that defines how to use the container to get inference results on a data set. This includes the configuration we need to invoke SageMaker batch transform:\n",
    "\n",
    "* The __instance count__ which is the number of machines to use to extract inferences\n",
    "* The __instance type__ which is the type of machine to use to extract inferences\n",
    "* The __output path__ determines where the inference results will be written"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using already existing model: sagemaker-decision-trees-2020-05-17-14-45-52-795\n"
     ]
    }
   ],
   "source": [
    "transform_output_folder = \"batch-transform-output\"\n",
    "output_path=\"s3://{}/{}\".format(sess.default_bucket(), transform_output_folder)\n",
    "\n",
    "transformer = tree.transformer(instance_count=1,\n",
    "                               instance_type='ml.m4.xlarge',\n",
    "                               output_path=output_path,\n",
    "                               assemble_with='Line',\n",
    "                               accept='text/csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use tranform() on the transfomer to get inference results against the data that we uploaded. You can use these options when invoking the transformer. \n",
    "\n",
    "* The __data_location__ which is the location of input data\n",
    "* The __content_type__ which is the content type set when making HTTP request to container to get prediction\n",
    "* The __split_type__ which is the delimiter used for splitting input data \n",
    "* The __input_filter__ which indicates the first column (ID) of the input will be dropped before making HTTP request to container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................\u001b[34mStarting the inference server with 4 workers.\u001b[0m\n",
      "\u001b[34m[2020-05-17 14:58:42 +0000] [10] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[34m[2020-05-17 14:58:42 +0000] [10] [INFO] Listening at: unix:/tmp/gunicorn.sock (10)\u001b[0m\n",
      "\u001b[34m[2020-05-17 14:58:42 +0000] [10] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2020-05-17 14:58:42 +0000] [15] [INFO] Booting worker with pid: 15\u001b[0m\n",
      "\u001b[34m[2020-05-17 14:58:42 +0000] [16] [INFO] Booting worker with pid: 16\u001b[0m\n",
      "\u001b[34m[2020-05-17 14:58:42 +0000] [17] [INFO] Booting worker with pid: 17\u001b[0m\n",
      "\u001b[34m[2020-05-17 14:58:42 +0000] [18] [INFO] Booting worker with pid: 18\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/May/2020:14:59:11 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/May/2020:14:59:11 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 150 records\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/May/2020:14:59:11 +0000] \"POST /invocations HTTP/1.1\" 200 1400 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\n",
      "\u001b[32m2020-05-17T14:59:11.446:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "transformer.transform(data_location, content_type='text/csv', split_type='Line', input_filter='$[1:]')\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on the configuration options, see [CreateTransformJob API](https://docs.aws.amazon.com/sagemaker/latest/dg/API_CreateTransformJob.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Output\n",
    "Lets read results of above transform job from s3 files and print output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform results: \n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s3_client = sess.boto_session.client('s3')\n",
    "s3_client.download_file(sess.default_bucket(), \"{}/iris.csv.out\".format(transform_output_folder), '/tmp/iris.csv.out')\n",
    "with open('/tmp/iris.csv.out') as f:\n",
    "    results = f.readlines()   \n",
    "print(\"Transform results: \\n{}\".format(''.join(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
