{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequence prediction often involves forecasting the next value in a real valued sequence or outputting a class label for an input sequence.\n",
    "\n",
    "This is often framed as a sequence of one input time step to one output time step (e.g. one-to-one) or multiple input time steps to one output time step (many-to-one) type sequence prediction problem.\n",
    "\n",
    "There is a more challenging type of sequence prediction problem that takes a sequence as input and requires a sequence prediction as output. These are called sequence-to-sequence prediction problems, or seq2seq for short.\n",
    "\n",
    "One modeling concern that makes these problems challenging is that the length of the input and output sequences may vary. Given that there are multiple input time steps and multiple output time steps, this form of problem is referred to as many-to-many type sequence prediction problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The approach to seq2seq prediction problems that has proven very effective is called the Encoder Decoder LSTM. This architecture is comprised of two models: one for reading the input sequence and encoding it into a ﬁxed-length vector, and a second for decoding the ﬁxed-length vector and outputting the predicted sequence.\n",
    "\n",
    "The use of the models in concert gives the architecture its name of Encoder-Decoder LSTM designed speciﬁcally for seq2seq problems.\n",
    "\n",
    "The Encoder-Decoder LSTM was developed for natural language processing problems where it demonstrated state-of-the-art performance, speciﬁcally in the area of text translation called statistical machine translation.\n",
    "\n",
    "The innovation of this architecture is the use of a **ﬁxed-sized internal representation** at the core of the model that input sequences are read to and output sequences are read from. For this reason, the method may be referred to as **sequence embedding**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image('C:/Users/Manoj/Desktop/Images/enc-dec lstm.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the interesting applications of encoder-decoder LSTM architecture:\n",
    "\n",
    "* **Machine Translation** e.g. English to French translation of phrases\n",
    "* **Learning to Execute** e.g. calculate the outcome of small programs\n",
    "* **Image Captioning** e.g. generating a text description for images\n",
    "* **Conversational Modeling** e.g. generating answers to textual questions\n",
    "* **Movement Classiﬁcation** e.g. generating a sequence of commands from a sequence of gestures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can think of the model as being comprised of two key parts: the encoder and the decoder. First, the input sequence is shown to the network one encoded character at a time.\n",
    "\n",
    "We need an encoding level to learn the relationship between the steps in the input sequence and develop an internal representation of these relationships.\n",
    "\n",
    "One or more LSTM layers can be used to implement the encoder model. The output of this model is a ﬁxed-size vector that represents the internal representation of the input sequence.\n",
    "\n",
    "The number of memory cells in this layer deﬁnes the length of this ﬁxed-sized vector.\n",
    "\n",
    "The decoder must transform the learned internal representation of the input sequence into the correct output sequence. One or more LSTM layers can also be used to implement the decoder model.\n",
    "\n",
    "The same weights can be used to output each time step in the output sequence by wrapping the Dense layer in a **TimeDistributed** wrapper.\n",
    "\n",
    "There’s a problem though. We must connect the encoder to the decoder, and they do not ﬁt. That is, the encoder will produce a 2-dimensional matrix of outputs, where the length is deﬁned by the number of memory cells in the layer.\n",
    "\n",
    "The decoder is an LSTM layer that expects a 3D input of [samples, time steps, features] in order to produce a decoded sequence of some different length deﬁned by the problem.\n",
    "\n",
    "We can solve this using a RepeatVector layer. This layer simply repeats the provided 2D input multiple times to create a 3D output.\n",
    "\n",
    "The RepeatVector layer can be used like an adapter to ﬁt the encoder and decoder parts of the network together. We can conﬁgure the RepeatVector to repeat the ﬁxed length vector one time for each time step in the output sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Addition Prediction Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The addition problem is a sequence-to-sequence, or seq2seq, prediction problem. It was used by Wojciech Zaremba and Ilya Sutskever in their 2014 paper exploring the capabilities of the Encoder-Decoder LSTM titled “Learning to Execute” where the architecture was demonstrated learning to calculate the output of small programs.\n",
    "\n",
    "The problem is deﬁned as calculating the sum output of two input numbers. This is challenging as each digit and mathematical symbol is provided as a character and the expected output is also expected as characters. For example, the input 10+6 with the output 16 would be represented by the sequences:\n",
    "\n",
    "* Input: [ ‘1’ , ‘0’ , ‘+’ , ‘6’] \n",
    "* Output: [ ‘1’ , ‘6’ ]\n",
    "\n",
    "The model must learn not only the integer nature of the characters, but also the nature of the mathematical operation to perform. \n",
    "\n",
    "Also notice how the number of digits could vary in both the input and output sequences.\n",
    "\n",
    "Technically this makes the addition prediction problem a sequence-to-sequence problem that requires a many-to-many model to address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image('C:/Users/Manoj/Desktop/Images/seq2seq.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's keep the problem simple with addition of two numbers, but we can see how this may be scaled to a variable number of terms and mathematical operations that could be given as input for the model to learn and generalize.\n",
    "\n",
    "We will divide this whole task into the following steps:\n",
    "\n",
    "1. Generate sum pairs\n",
    "2. Integers to Padded Strings\n",
    "3. Integer Encoded Sequences\n",
    "4. One Hot Encoded Sequences\n",
    "5. Sequence Generation Pipeline\n",
    "6. Decode Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ﬁrst step is to generate sequences of random integers and their sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed \n",
    "from random import randint\n",
    "import numpy as np\n",
    "# generate lists of random integers and their sum\n",
    "def random_sum_pairs(n_examples, n_numbers, largest):\n",
    "    X, y = list(), list()\n",
    "    for i in range(n_examples):\n",
    "        in_pattern = [randint(1,largest) for _ in range(n_numbers)]\n",
    "        out_pattern = sum(in_pattern)\n",
    "        X.append(in_pattern)\n",
    "        y.append(out_pattern)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 10]] [13]\n"
     ]
    }
   ],
   "source": [
    "#test function\n",
    "seed(1) \n",
    "n_samples = 1 \n",
    "n_numbers = 2 \n",
    "largest = 10 \n",
    "# generate pairs \n",
    "X, y = random_sum_pairs(n_samples, n_numbers, largest)\n",
    "print(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to convert the integers to strings. The input string will have the format ‘10+10’ and the output string will have the format ‘20’. Key to this function is the padding of numbers to ensure that each input and output sequence has the same number of characters.\n",
    "\n",
    "A padding character should be different from the data so the model can learn to ignore them. In this case, we use the space character for padding(‘ ’) and pad the string on the left, keeping the information on the far right.\n",
    "\n",
    "Padding requires us to know how long the longest sequence may be.\n",
    "\n",
    "We can calculate this easily by taking the log10() of the largest integer we can generate and the ceiling of that number to get an idea of how many chars are needed for each number.\n",
    "\n",
    "We add 1 to the largest number to ensure we expect 3 chars instead of 2 chars for the case of a round largest number, like 200 and take the ceiling of the result (e.g. ceil(log10(largest+1))). We then need to add the right number of plus symbols (e.g. n numbers-1).\n",
    "\n",
    "max_length = n_numbers * ceil(log10(largest+1)) + n_numbers – 1\n",
    "\n",
    "Let's make this concrete with a worked example where the total number of terms (n numbers) is 3 and the largest value (largest) is 10.\n",
    "\n",
    "* max_length = 3 * ceil(log10(10+1))+3-1\n",
    "* max_length = 3 * ceil(1.0413926851582251)+3-1\n",
    "* max_length = 8\n",
    "\n",
    "Intuitively, we would expect 2 spaces for each term (e.g. [‘1’,‘0’]) multiplied by 3 terms, or a maximum length of input sequences of 6 spaces with two more spaces for the addition symbols (e.g. [‘1’,‘0’,‘+’,‘1’,‘0’,‘+’,‘1’,‘0’]) making the largest possible sequence 8 characters in length. \n",
    "\n",
    "we can calculate the expected maximum output sequence length for the above example with the total number of terms (n numbers) is 3 and the largest value (largest) is 10.\n",
    "\n",
    "* max_length = ceil(log10(n_numbers * (largest+1)))\n",
    "* max_length = 2\n",
    "\n",
    "Again, intuitively, we would expect the largest possible addition to be 10+10+10 or the value of 30. This would require a maximum length of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil, log10\n",
    "# convert data to strings \n",
    "def to_string(X, y, n_numbers, largest):\n",
    "    max_length = n_numbers * ceil(log10(largest+1)) + n_numbers - 1\n",
    "    Xstr = list()\n",
    "    for pattern in X:\n",
    "        strp = '+'.join([str(n) for n in pattern])\n",
    "        strp = ''.join(['' for _ in range(max_length-len(strp))]) + strp\n",
    "        Xstr.append(strp)\n",
    "    max_length = ceil(log10(n_numbers * (largest+1)))\n",
    "    ystr = list()\n",
    "    for pattern in y:\n",
    "        strp = str(pattern)\n",
    "        strp = ''.join(['' for _ in range(max_length-len(strp))]) + strp\n",
    "        ystr.append(strp)\n",
    "    return Xstr, ystr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 10]] [13]\n",
      "['3+10'] ['13']\n"
     ]
    }
   ],
   "source": [
    "#test function\n",
    "seed(1) \n",
    "n_samples = 1 \n",
    "n_numbers = 2 \n",
    "largest = 10\n",
    "\n",
    "# generate pairs \n",
    "X, y = random_sum_pairs(n_samples, n_numbers, largest) \n",
    "print(X, y)\n",
    "\n",
    "# convert to strings \n",
    "X, y = to_string(X, y, n_numbers, largest) \n",
    "print(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to encode each character in the string as an integer value. We have to work with numbers in neural networks after all, not characters. Integer encoding transforms the problem into a classiﬁcation problem where the output sequence may be considered class outputs with 11 possible values each.\n",
    "\n",
    "This just so happens to be integers with some ordinal relationship (the ﬁrst 10 class values). To perform this encoding, we must deﬁne the full alphabet of symbols that may appear in the string encoding, as follows:\n",
    "\n",
    "alphabet = [ ‘0’ ,’1’ ,’2’ ,’3’ ,’4’ ,’5’ ,’6’ ,’7’ ,’8’ ,’9’ ,’+’ ,’ ’ ]\n",
    "\n",
    "Integer encoding then becomes a simple process of building a lookup table of character-to integer offset and converting each char of each string, one by one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode strings \n",
    "def integer_encode(X, y, alphabet):\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "    Xenc = list()\n",
    "    for pattern in X:\n",
    "        integer_encoded = [char_to_int[char] for char in pattern]\n",
    "        Xenc.append(integer_encoded)\n",
    "    yenc = list()\n",
    "    for pattern in y:\n",
    "        integer_encoded = [char_to_int[char] for char in pattern]\n",
    "        yenc.append(integer_encoded)\n",
    "    return Xenc, yenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 10]] [13]\n",
      "['3+10'] ['13']\n",
      "[[3, 10, 1, 0]] [[1, 3]]\n"
     ]
    }
   ],
   "source": [
    "seed(1) \n",
    "n_samples = 1 \n",
    "n_numbers = 2 \n",
    "largest = 10 \n",
    "# generate pairs \n",
    "X, y = random_sum_pairs(n_samples, n_numbers, largest) \n",
    "print(X, y) \n",
    "# convert to strings \n",
    "X, y = to_string(X, y, n_numbers, largest) \n",
    "print(X, y) \n",
    "# integer encode \n",
    "alphabet = ['0','1','2','3','4','5','6','7','8','9','+',''] \n",
    "X, y = integer_encode(X, y, alphabet) \n",
    "print(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to binary encode the integer encoding sequences. This involves converting each integer to a binary vector with the same length as the alphabet and marking the speciﬁc integer with a 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode \n",
    "def one_hot_encode(X, y, max_int):\n",
    "    Xenc = list()\n",
    "    for seq in X:\n",
    "        pattern = list()\n",
    "        for index in seq:\n",
    "            vector = [0 for _ in range(max_int)]\n",
    "            vector[index] = 1\n",
    "            pattern.append(vector)\n",
    "        Xenc.append(pattern)\n",
    "    yenc = list()\n",
    "    for seq in y:\n",
    "        pattern = list()\n",
    "        for index in seq:\n",
    "            vector = [0 for _ in range(max_int)]\n",
    "            vector[index] = 1\n",
    "            pattern.append(vector)\n",
    "        yenc.append(pattern)\n",
    "    return Xenc, yenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 10]] [13]\n",
      "['3+10'] ['13']\n",
      "[[3, 10, 1, 0]] [[1, 3]]\n",
      "[[[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]] [[[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]]]\n"
     ]
    }
   ],
   "source": [
    "seed(1) \n",
    "n_samples = 1 \n",
    "n_numbers = 2 \n",
    "largest = 10 \n",
    "# generate pairs \n",
    "X, y = random_sum_pairs(n_samples, n_numbers, largest) \n",
    "print(X, y) \n",
    "# convert to strings \n",
    "X, y = to_string(X, y, n_numbers, largest) \n",
    "print(X, y) \n",
    "# integer encode \n",
    "alphabet = ['0','1','2','3','4','5','6','7','8','9','+',''] \n",
    "X, y = integer_encode(X, y, alphabet) \n",
    "print(X, y)\n",
    "# one hot encode \n",
    "X, y = one_hot_encode(X, y, len(alphabet)) \n",
    "print(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sequence Generation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate an encoded dataset \n",
    "def generate_data(n_samples, n_numbers, largest, alphabet): \n",
    "    # generate pairs \n",
    "    X, y = random_sum_pairs(n_samples, n_numbers, largest) \n",
    "    # convert to strings \n",
    "    X, y = to_string(X, y, n_numbers, largest) \n",
    "    # integer encode \n",
    "    X, y = integer_encode(X, y, alphabet) \n",
    "    # one hot encode \n",
    "    X, y = one_hot_encode(X, y, len(alphabet)) \n",
    "    # return as NumPy arrays \n",
    "    X, y = np.array(X), np.array(y) \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to invert the encoding to convert the output vectors back into numbers so we can compare expected output integers to predicted integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert encoding \n",
    "def invert(seq, alphabet):\n",
    "    int_to_char = dict((i, c) for i, c in enumerate(alphabet))\n",
    "    strings = list()\n",
    "    for pattern in seq:\n",
    "        string = int_to_char[argmax(pattern)]\n",
    "        strings.append(string)\n",
    "    return ''.join(strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define and Compile the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ﬁrst step is to deﬁne the speciﬁcations of the sequence prediction problem. We need to specify 3 parameters as input to the generate_data() function (above) for generating samples of input-output sequences:\n",
    "\n",
    "* n_terms: The number of terms in the equation, (e.g. 2 for10+10)\n",
    "* largest: The largest numerical value for each term (e.g. 10 for values between 1-10)\n",
    "* alphabet: The symbols used to encode the input and output sequences (e.g. 0-9, + and '')\n",
    "\n",
    "Let's configure the problem where each instance will be comprised of 3 terms with the maximum value of 10 per term. The alphabet remains ﬁxed regardless of conﬁguration with the values 0-9, ‘+’, and ‘ ’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of math terms \n",
    "n_terms = 3 \n",
    "# largest value for any single input digit \n",
    "largest = 10 \n",
    "# scope of possible symbols for each input or output time step \n",
    "alphabet = [str(x) for x in range(10)] + ['+','']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, the network needs 3 more conﬁguration values deﬁned by the speciﬁcation of the addition problem:\n",
    "\n",
    "* n_chars: The size of the alphabet for a single time step (e.g. 12 for 0-9, ‘+’ and '')\n",
    "* n_in_seq_length: The number of time steps of encoded input sequences (e.g. 8 for ‘10+10+10’)\n",
    "* n_out_seq_length: The number of time steps of an encoded output sequence (e.g. 2 for ‘30’)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of alphabet: (12 for 0-9, + and ) \n",
    "n_chars = len(alphabet)\n",
    "# length of encoded input sequence (8 for 10+10+10) \n",
    "n_in_seq_length = n_terms * ceil(log10(largest+1)) + n_terms - 1\n",
    "# length of encoded output sequence (2 for 30 )\n",
    "n_out_seq_length = ceil(log10(n_terms * (largest+1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now define Encoder-Decoder LSTM. We will use a single LSTM layer for the encoder and another single layer for the decoder.\n",
    "\n",
    "The encoder is deﬁned with 75 memory cells and the decoder with 50 memory cells. The asymmetry in layer sizes in the encoder and decoder seems like a natural organization given that input sequences are relatively longer than output sequences.\n",
    "\n",
    "The output layer uses the categorical log loss for the 12 possible classes that may be predicted. The efficient Adam implementation of gradient descent is used and accuracy will be calculated during training and model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 75)                26400     \n",
      "_________________________________________________________________\n",
      "repeat_vector_2 (RepeatVecto (None, 2, 75)             0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 2, 50)             25200     \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 2, 12)             612       \n",
      "=================================================================\n",
      "Total params: 52,212\n",
      "Trainable params: 52,212\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, TimeDistributed, RepeatVector\n",
    "# define encoder-decoder LSTM \n",
    "model = Sequential() \n",
    "model.add(LSTM(75, input_shape=(n_in_seq_length, n_chars)))\n",
    "model.add(RepeatVector(n_out_seq_length))\n",
    "model.add(LSTM(50, return_sequences=True)) \n",
    "model.add(TimeDistributed(Dense(n_chars, activation= 'softmax'))) \n",
    "model.compile(loss= 'categorical_crossentropy', optimizer= 'adam', metrics=['acc']) \n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model is fitted on a single epoch of 75,000 randomly generated instances of input-output pairs. The number of sequences is a proxy for the number of training epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected lstm_3_input to have 3 dimensions, but got array with shape (75000, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-565d4463ddcc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# fit model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m75000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlargest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malphabet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1154\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    133\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    136\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected lstm_3_input to have 3 dimensions, but got array with shape (75000, 1)"
     ]
    }
   ],
   "source": [
    "# fit model \n",
    "X, y = generate_data(75000, n_terms, largest, alphabet) \n",
    "model.fit(X, y, epochs=1, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
